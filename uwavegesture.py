# -*- coding: utf-8 -*-
"""UWaveGesture.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qYBbQtMzFpGMPe5Nd2tSsLu4DQo1vEmn
"""

!pip install liac-arff

!pip install pycaret

!sudo apt remove python3-blinker

pip show blinker

pip install --upgrade --force-reinstall blinker

!pip install pycaret[full]

import pandas as pd
import arff
import numpy as np

# Load the ARFF file, handle the relational attribute
def load_arff_file(filepath):
    with open(filepath, 'r') as file:
        # Read the ARFF file content
        content = file.readlines()

    # Find the start of the data section
    data_start_index = content.index('@data\n') + 1

    # Extract attribute names (excluding relational attribute)
    attribute_lines = [line for line in content[:data_start_index - 1] if line.startswith('@attribute')]
    attribute_names = [line.split()[1] for line in attribute_lines if not line.startswith('@attribute relationalAtt')]  # Exclude relational attribute

    # Extract the data
    data_lines = content[data_start_index:]

    # Parse the data lines into a list of lists
    data = []
    max_cols = 0 # Initialize a variable to track the maximum number of columns
    for line in data_lines:
        # Assuming data is comma-separated
        values = [v.strip() for v in line.strip().split(',')]
        if(values and values[0] != ''):
            data.append(values)
            max_cols = max(max_cols, len(values)) # Update max_cols if current row has more columns

    # Adjust attribute_names based on the actual number of columns if needed
    if len(attribute_names) != max_cols:
        # If a mismatch is detected, create generic column names
        attribute_names = [f'col_{i}' for i in range(max_cols)]

    # Create DataFrame without the relational attribute
    df = pd.DataFrame(data, columns=attribute_names)

    # Convert numerical columns to appropriate types
    for col in attribute_names:
        try:
            df[col] = pd.to_numeric(df[col])
        except ValueError:
            pass  # Ignore columns that can't be converted

    return df

# Load the file
train_df = load_arff_file('/content/UWaveGestureLibrary_TRAIN.arff')

# Display the DataFrame
print(train_df.head())

print(f"\nNumber of rows in the DataFrame: {len(train_df)}")

# Check the distribution of class labels (assuming the last column is the label)
print("Class Distribution:")
print(train_df.iloc[:, -1].value_counts())  # Modify if your label column is not the last one

# Load the test file
test_df = load_arff_file('/content/UWaveGestureLibrary_TEST.arff')

# Separate features and labels for the test set

# Check for non-numeric values in the DataFrame
non_numeric_train = train_df.applymap(lambda x: isinstance(x, str) and not x.replace('.', '', 1).isdigit())
non_numeric_test = test_df.applymap(lambda x: isinstance(x, str) and not x.replace('.', '', 1).isdigit())

print("Non-numeric values in training set:")
print(train_df[non_numeric_train.any(axis=1)])

print("Non-numeric values in test set:")
print(test_df[non_numeric_test.any(axis=1)])

# Remove the trailing quotes and convert to numeric
train_df = train_df.applymap(lambda x: pd.to_numeric(x.replace("'", "") if isinstance(x, str) else x, errors='coerce'))
test_df = test_df.applymap(lambda x: pd.to_numeric(x.replace("'", "") if isinstance(x, str) else x, errors='coerce'))

import pandas as pd

# Assume df_train is your training DataFrame

# Remove leading and trailing single quotes and any non-numeric characters
train_df = train_df.applymap(lambda x: str(x).replace("'", "").strip() if isinstance(x, str) else x)

# Convert the DataFrame to numeric, coercing errors (so that any non-convertible values are turned to NaN)
train_df = train_df.apply(pd.to_numeric, errors='coerce')

# Verify if there are still any non-numeric values
print("Non-numeric values after cleaning:")
print(train_df[train_df.applymap(lambda x: not pd.api.types.is_number(x)).any(axis=1)])

# Check for NaN values
print("Number of NaN values in each column:")
print(train_df.isna().sum())
print(test_df.isna().sum())

# Recheck if there are still non-numeric values
non_numeric_train = train_df.applymap(lambda x: isinstance(x, str) and not x.replace('.', '', 1).isdigit())
non_numeric_test = test_df.applymap(lambda x: isinstance(x, str) and not x.replace('.', '', 1).isdigit())

# Display rows with non-numeric values
print("Non-numeric values in training set:")
print(train_df[non_numeric_train])

print("Non-numeric values in test set:")
print(test_df[non_numeric_test])

print(train_df.isnull().sum().sum())
print(test_df.isnull().sum().sum())

print(train_df.columns)



# Set the target column as 'col_943'
X_train = train_df.drop(columns=['col_943'])  # Drop the target column from the training features
y_train = train_df['col_943']  # Use 'col_943' as the target variable

X_test = test_df.drop(columns=['col_943'])  # Drop the target column from the testing features
y_test = test_df['col_943']  # Use 'col_943' as the target variable for testing

from pycaret.classification import setup, compare_models

# Combine features and target into one DataFrame for setup
train_df['gesture'] = y_train  # Ensure 'gesture' is the column name of the target

# Run the setup function, replacing 'silent=True' with 'verbose=False'
clf_setup = setup(data=train_df, target='gesture', verbose=False, session_id=123)

# Compare baseline models to understand which performs best
best_model = compare_models()

# Check that the target column exists
print(train_df.columns)
print(test_df.columns)

# Ensure 'col_943' is set as the target variable in both train_df and test_df
X_train = train_df.drop(columns=['col_943'])  # Drop target column from training set
y_train = train_df['col_943']  # Target column in training set

X_test = test_df.drop(columns=['col_943'])  # Drop target column from testing set
y_test = test_df['col_943']  # Target column in testing set

# Now both train_df and test_df should have the correct columns for features and target

from pycaret.classification import setup, compare_models

# Combine features and target back into a single DataFrame for PyCaret
train_df = X_train.copy()
train_df['col_943'] = y_train  # 'col_943' as the target column

test_df = X_test.copy()
test_df['col_943'] = y_test  # 'col_943' as the target column

# Reset index of both train_df and test_df before passing to setup
train_df.reset_index(drop=True, inplace=True)  # Reset index and drop the old index column
test_df.reset_index(drop=True, inplace=True)  # Reset index and drop the old index column


# Run the setup function, providing your custom train_df and specifying index=False
clf_setup = setup(data=train_df, target='col_943', test_data=test_df, verbose=False, session_id=123, index=False)  # index=False to avoid index issues

# Compare models
best_model = compare_models()

from pycaret.classification import setup, compare_models, create_model  # Import functions

# Add the target variable column to both train_df and test_df
train_df = X_train.copy()
train_df['col_943'] = y_train  # Add target column

test_df = X_test.copy()
test_df['col_943'] = y_test  # Add target column

# Reset index of both train_df and test_df before passing to setup
train_df.reset_index(drop=True, inplace=True)
test_df.reset_index(drop=True, inplace=True)

# Initialize the setup in PyCaret
# Pass train_df to setup() to initialize the PyCaret environment
setup(data=train_df, target='col_943', session_id=123)

# Create the model (Extra Trees in this case)
et = create_model('et')

# Optional: Compare models if need

# Import necessary functions from PyCaret
from pycaret.classification import setup, create_model, tune_model, compare_models

# Add the target variable column to both train_df and test_df
train_df = X_train.copy()
train_df['col_943'] = y_train  # Add target column

test_df = X_test.copy()
test_df['col_943'] = y_test  # Add target column

# Reset index of both train_df and test_df before passing to setup
train_df.reset_index(drop=True, inplace=True)
test_df.reset_index(drop=True, inplace=True)

# Initialize the PyCaret setup with the training dataset
setup(data=train_df, target='col_943', session_id=123)

# Create the model (Extra Trees in this case)
et = create_model('et')

# Optional: Compare models (if needed, after creating the model)
# best_model = compare_models()

# Now, tune the Extra Trees model
tuned_et = tune_model(et)

# After tuning, you can evaluate the tuned model
tuned_et

# Import necessary functions from PyCaret
from pycaret.classification import setup, create_model, tune_model, ensemble_model

# Add the target variable column to both train_df and test_df
train_df = X_train.copy()
train_df['col_943'] = y_train  # Add target column

test_df = X_test.copy()
test_df['col_943'] = y_test  # Add target column

# Reset index of both train_df and test_df before passing to setup
train_df.reset_index(drop=True, inplace=True)
test_df.reset_index(drop=True, inplace=True)

# Initialize the PyCaret setup with the training dataset
setup(data=train_df, target='col_943', session_id=123)

# Create the model (Extra Trees in this case)
et = create_model('et')

# Optional: Tune the model if desired (this step is optional)
tuned_et = tune_model(et)

# Ensemble the model using bagging or boosting (default ensemble method)
ensembled_et = ensemble_model(et)  # This will apply bagging by default

# If you want to apply boosting, you can specify 'boosting' as a parameter
# ensembled_et_boost = ensemble_model(et, method='boosting')  # Use boosting for ensemble

# View the ensembled model
ensembled_et

from pycaret.classification import save_model

# Save the trained model
save_model(et, 'et_model')